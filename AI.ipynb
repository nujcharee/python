{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f9b8c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978f6d7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69b2ffc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3cdd027",
   "metadata": {},
   "source": [
    "Introduction:\n",
    "Imbalanced dataset can impact the accuracy of classication models. Using `Logistic Regression` as a baseline. \n",
    "In the `pre-processing` step, I will perform a task that detect / remove anomalous data \n",
    "Outliers, or anomalies, can impact the accuracy of both regression and classification models, so detecting and removing them is an important step in the machine learning process. On larger datasets, detecting and removing outliers is much harder, so data scientists often apply automated anomaly detection algorithms, such as the Isolation Forest, to help identify and remove outliers.\n",
    "\n",
    "As the name suggests, the Isolation Forest is a tree-based anomaly detection algorithm. It uses an unsupervised learning approach to detect unusual data points which can then be removed from the training data. The re-training of the model on a data set with the outliers removed generally sees performance increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c829f1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # for data manipulation\n",
    "\n",
    "from sklearn.cluster import DBSCAN # for building a clustering model\n",
    "from sklearn.preprocessing import MinMaxScaler # for feature scaling\n",
    "from sklearn import metrics # for calculating Silhouette score\n",
    "\n",
    "import matplotlib.pyplot as plt # for data visualization\n",
    "import plotly.graph_objects as go # for data visualization\n",
    "import plotly.express as px # for data visualization\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35201ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train  = pd.read_csv(\"df_train.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc4a17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"s3://dash-879281191186-prod-s3-data-wip/jbc-edge-manual-data-egress/sgss/sgss_positve_ct_results/v1/full/sgss_positive_ct_results_20211123.csv\"\n",
    "df = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e73be6",
   "metadata": {},
   "source": [
    "- Error if Delta and S_Gene is not present\n",
    "- Alpha doesnt have S_Gene\n",
    "- If still see recent alpha, possibly error due to low prevalence in population.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fed399",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.where(df.LFT_Flag.str.contains('PCR') & ~df.LFT_Flag.str.contains)\n",
    "df = df[(df.Specimen_Date.notna()) & (df.LFT_Flag.str.contains('PCR')) ]\n",
    "df['Delta'] = np.where((df.VAM_Profile=='B.1.617.2') | (df.VAM_Profile=='VOC-21APR-02'),1,0)\n",
    "\n",
    "df_train = df[(df.Delta==1) | (df.VAM_Profile=='UNDETERMINED')].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d899edfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ORF1ab'] = pd.to_numeric(df['ORF1ab'], errors='coerce').dropna()\n",
    "df['N gene'] = pd.to_numeric(df['N gene'], errors='coerce').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3913c59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_test = df.copy()\n",
    "delta_test = delta_test[~(delta_test['ORF1ab']==0) & ~(delta_test['N gene']==0) & ~(delta_test['S gene']==0)]\n",
    "delta_test = delta_test[delta_test['Delta']==1]\n",
    "delta_test = delta_test[['ORF1ab' , 'N gene', 'S gene']]\n",
    "\n",
    "\n",
    "ndelta_test = df[df['VAM_Profile']==\"UNDETERMINED\"]\n",
    "ndelta_test = ndelta_test[~(ndelta_test['ORF1ab']==0) & ~(ndelta_test['N gene']==0) & ~(ndelta_test['S gene']==0)]\n",
    "ndelta_test = ndelta_test[['ORF1ab' , 'N gene', 'S gene']]\n",
    "\n",
    "len(ndelta_test) / (len(ndelta_test)+len(delta_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac971e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(delta_test[['ORF1ab' , 'N gene', 'S gene']])\n",
    "sns.pairplot(ndelta_test[['ORF1ab' , 'N gene', 'S gene']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fe70d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['N gene'] = pd.to_numeric(df_train['N gene'], downcast=\"float\")\n",
    "df_train['ORF1ab'] = pd.to_numeric(df_train['ORF1ab'], downcast=\"float\")\n",
    "gene = ['Specimen_Date', 'ORF1ab' , 'N gene', 'S gene', 'Delta', 'Symptomatic', 'TRAVEL_ABROAD_INDICATOR', 'Patient_Sex', 'age_group']\n",
    "df_train = df_train[gene]\n",
    "df_train.info()\n",
    "#df_train[df_train[gene].sum(axis=1)>0].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d96a95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea86d304",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head(10).to_csv(\"small.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea85ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gene target of interest \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90e4c6c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORF1ab</th>\n",
       "      <th>N gene</th>\n",
       "      <th>S gene</th>\n",
       "      <th>Delta</th>\n",
       "      <th>Symptomatic</th>\n",
       "      <th>Patient_Sex</th>\n",
       "      <th>age_group</th>\n",
       "      <th>SGTF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7398</th>\n",
       "      <td>27.66</td>\n",
       "      <td>28.25</td>\n",
       "      <td>25.67</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35-44</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ORF1ab  N gene  S gene  Delta  Symptomatic  Patient_Sex age_group  SGTF\n",
       "7398   27.66   28.25   25.67      0            1            0     35-44   NaN"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda2e879",
   "metadata": {},
   "source": [
    "Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804e3101",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.pairplot(df_train[['ORF1ab','N gene', 'S gene']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a194fd",
   "metadata": {},
   "source": [
    "Look at categorical variables\n",
    "- Travel abroad highly imbalanced, remove it\n",
    "- around 51:49 female:male proportion in the sample\n",
    "- around 63:37 Symptomatic proportion in the sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b0bfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.TRAVEL_ABROAD_INDICATOR.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0a879c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.Patient_Sex.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8764438e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.Symptomatic.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1293a686",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.age_group.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00640ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape \n",
    "#(740980)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3ec8ee",
   "metadata": {},
   "source": [
    "#### Handling missing data\n",
    "- Impute\n",
    "- Remove errors\n",
    "- Remove variables with no power or 0 sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bff9617",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Error: -1 value\n",
    "df_train = df_train[~((df_train['ORF1ab']<0) | (df_train['N gene']<0) | (df_train['S gene']<0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0723ae99",
   "metadata": {},
   "outputs": [],
   "source": [
    "## \n",
    "df_train.TRAVEL_ABROAD_INDICATOR.value_counts()\n",
    "df_train = df_train.drop(['TRAVEL_ABROAD_INDICATOR'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf714252",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Symptomatic'] = np.where(df_train['Symptomatic']==\"Y\",1,0)\n",
    "df_train['Patient_Sex'] = np.where(df_train['Patient_Sex']==\"Female\",1,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087fb370",
   "metadata": {},
   "outputs": [],
   "source": [
    "## feature engineering\n",
    "df_train['SGTF'] = df_train[(df_train['ORF1ab']>0) & (df_train['N gene']>0) & (df_train['S gene']==0)][['ORF1ab', 'N gene']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71b2f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a16f33f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 740980 entries, 7398 to 8011514\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   ORF1ab       740980 non-null  float64\n",
      " 1   N gene       740980 non-null  float64\n",
      " 2   S gene       740980 non-null  float64\n",
      " 3   Delta        740980 non-null  int64  \n",
      " 4   Symptomatic  740980 non-null  int64  \n",
      " 5   Patient_Sex  740980 non-null  int64  \n",
      " 6   age_group    740963 non-null  object \n",
      " 7   SGTF         0 non-null       float64\n",
      "dtypes: float64(4), int64(3), object(1)\n",
      "memory usage: 50.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde4774f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns \n",
    "#sns.displot(df_train, x=\"ORF1ab\", kind=\"kde\")\n",
    "df_train = df_train[~(df_train['ORF1ab']==0) & ~(df_train['N gene']==0) & ~(df_train['S gene']==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c265eaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train.to_csv(\"df_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769b41da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.displot(df_train, x=\"N gene\", kind=\"kde\")\n",
    "ct = df_train[['Patient_Sex', 'ORF1ab']].melt(id_vars='Patient_Sex', var_name='ORF1ab', value_name='Ct').append(\n",
    "            df_train[['Patient_Sex', 'N gene']].melt(id_vars='Patient_Sex', var_name='ORF1ab', value_name='Ct')).append(\n",
    "            df_train[['Patient_Sex', 'S gene']].melt(id_vars='Patient_Sex', var_name='ORF1ab', value_name='Ct')\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff0eb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = ct.rename(columns={\"ORF1ab\": \"Gene\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19022a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(ct, x=\"Ct\", hue=\"Gene\", kind=\"kde\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f38c344",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "247f1d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df_train['age_group'])\n",
    "df_train['age_group'] = le.transform(df_train['age_group'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b12b776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ORF1ab', 'N gene', 'S gene', 'Delta', 'Symptomatic', 'Patient_Sex',\n",
       "       'age_group', 'SGTF'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fae5e080",
   "metadata": {},
   "outputs": [],
   "source": [
    "## normalise 3 numerical columns\n",
    "scaler = StandardScaler()\n",
    "#roburst = RobustScaler()\n",
    "X = df_train[['ORF1ab', 'N gene', 'S gene','Symptomatic', 'Patient_Sex','age_group']]\n",
    "scaler.fit(X)\n",
    "StandardScaler()\n",
    "scale_X = scaler.transform(X)\n",
    "\n",
    "#sns.displot(scale_X, kind=\"kde\")\n",
    "\n",
    "#sns.displot(roburst_X, kind=\"kde\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add65d87",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b92ab23",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Week number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf29522",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train['date']=pd.to_datetime(df_train['Specimen_Date'])\n",
    "#df_train['date'] = pd.to_datetime(df_train['date'])\n",
    "#df_train['week'] =  df['date'] - pd.to_timedelta(df_train['date'].dt.weekday, unit='D')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d9188c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Alpha isnt new so will drop it and only look at Delta and others\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154f573a",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = df_train[df_train.Delta==1]\n",
    "other = df_train[df_train.Delta==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd7eba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proportion of data\n",
    "len(delta)/(len(delta)+len(other))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14927f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,accuracy_score, fbeta_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.covariance import EllipticEnvelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad964bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_classes = pd.value_counts(df_train['Delta'], sort = True)\n",
    "_ =count_classes.plot(kind = 'bar', rot=0)\n",
    "plt.title(\"Variant Distribution\")\n",
    "plt.xticks(range(len(df_train['Delta'].unique())), df_train['Delta'].unique())\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91099d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.Delta.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c1969a",
   "metadata": {},
   "source": [
    "## Start here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d602a19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "addf7ef8",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "For such an imbalanced dataset, a useful baseline can be to beat the 'Null Accuracy', and in our case, since we're looking for the negative ('Not Delta'), I will take the inverse of that. In other words, always predicting the most common outcome.\n",
    "\n",
    "For this case, 14078/(726902+14078) = ~0.02\n",
    "\n",
    "So a good target to beat would be 2.5%~ for recall for specimen other then of delta variant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a36bd33",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.8.1-py3-none-any.whl (189 kB)\n",
      "\u001b[K     |████████████████████████████████| 189 kB 14.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn>=0.24 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from imbalanced-learn->imblearn) (0.24.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from imbalanced-learn->imblearn) (1.19.5)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from imbalanced-learn->imblearn) (1.5.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from imbalanced-learn->imblearn) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from scikit-learn>=0.24->imbalanced-learn->imblearn) (2.1.0)\n",
      "Installing collected packages: imbalanced-learn, imblearn\n",
      "Successfully installed imbalanced-learn-0.8.1 imblearn-0.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting boruta\n",
      "  Downloading Boruta-0.3-py3-none-any.whl (56 kB)\n",
      "\u001b[K     |████████████████████████████████| 56 kB 6.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.10.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boruta) (1.19.5)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boruta) (1.5.3)\n",
      "Requirement already satisfied: scikit-learn>=0.17.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boruta) (0.24.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from scikit-learn>=0.17.1->boruta) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from scikit-learn>=0.17.1->boruta) (1.0.1)\n",
      "Installing collected packages: boruta\n",
      "Successfully installed boruta-0.3\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install imblearn\n",
    "!pip install boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84fdfe0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    726902\n",
       "1     14078\n",
       "Name: Subvariant, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Subvariant'] = np.where(df_train['Delta']==1,0,1)\n",
    "df_train['Subvariant'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821e198a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Subvariant'].value_counts()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed3a925c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, recall_score, roc_auc_score, precision_score, f1_score\n",
    "import shap\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "73109e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inverse of Null Accuracy:  0.018999163270263703\n",
      "Null Accuracy:  0.9810008367297363\n"
     ]
    }
   ],
   "source": [
    "print('Inverse of Null Accuracy: ',14078/(14078+726902))\n",
    "print('Null Accuracy: ',726902/(14078+726902))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "24ea0d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ORF1ab', 'N gene', 'S gene', 'Delta', 'Symptomatic', 'Patient_Sex',\n",
       "       'age_group', 'Subvariant'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Subvariant'].value_counts()\n",
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "793db665",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Target data \n",
    "y = df_train['Subvariant']\n",
    "X = df_train[['age_group', 'ORF1ab','N gene', 'S gene', 'Symptomatic', 'Patient_Sex']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc036c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.5, stratify=y, random_state=111)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.5, random_state=1) # 0.25 x 0.8 = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9d1bb48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(185245, 6)\n",
      "(185245, 6)\n",
      "(370490, 6)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f70be4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE()\n",
    "X_train_resh, y_train_resh = oversample.fit_resample(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdcad9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_log = Pipeline(steps = [('scale',StandardScaler()),('LR',LogisticRegression(random_state=111))])\n",
    "clflog_cv = cross_val_score(clf_log,X_train_resh,y_train_resh,cv=10,scoring='f1')\n",
    "\n",
    "print('Mean f1 scores:')\n",
    "print('Logistic Regression mean :',cross_val_score(clf_log ,X_train_resh,y_train_resh,cv=10,scoring='f1').mean())\n",
    "print('Logistic Regression recall :',cross_val_score(clf_log ,X_train_resh,y_train_resh,cv=10,scoring='recall').mean())\n",
    "print('Logistic Regression F2 :',cross_val_score(clf_log ,X_train_resh,y_train_resh,cv=10,scoring='beta2').mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb793915",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_log.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a9eb329",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state=111)\n",
    "# fit the model\n",
    "model.fit(X, y)\n",
    "importance = model.coef_[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a476f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: 0.00590\n",
      "Feature: 1, Score: 0.06400\n",
      "Feature: 2, Score: -0.10339\n",
      "Feature: 3, Score: 0.19560\n",
      "Feature: 4, Score: -0.01984\n",
      "Feature: 5, Score: 0.00963\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "importance = model.coef_[0]\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c94706c",
   "metadata": {},
   "source": [
    "Notice that the coefficients are both positive and negative. The positive scores indicate a feature that predicts class 1, whereas the negative scores indicate a feature that predicts class 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "04fe88cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age_group', 'ORF1ab', 'N gene', 'S gene', 'Symptomatic',\n",
       "       'Patient_Sex'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3e43dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from boruta import BorutaPy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=200, n_jobs=-1, max_depth=5)\n",
    "\n",
    "trans = BorutaPy(clf, random_state=42, verbose=2)\n",
    "sel = trans.fit_transform(X.values, y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1b89ca85",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_log.fit(X_train_resh,y_train_resh)\n",
    "pred   = clf_log.predict(X_test)\n",
    "logreg_cm  = confusion_matrix(y_test,pred )\n",
    "\n",
    "clf_f1  = f1_score(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b054bfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean f1 scores:')\n",
    "print('LR mean :',clf_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "56a3fcf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.67      0.80    363451\n",
      "           1       0.03      0.58      0.06      7039\n",
      "\n",
      "    accuracy                           0.67    370490\n",
      "   macro avg       0.51      0.63      0.43    370490\n",
      "weighted avg       0.97      0.67      0.79    370490\n",
      "\n",
      "Accuracy Score:  0.6714081351723393\n",
      "F1 Score:  0.0628175519630485\n",
      "F2 Score:  0.13508412960130317\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,pred))\n",
    "print('Accuracy Score: ',accuracy_score(y_test,pred))\n",
    "print('F1 Score: ',f1_score(y_test,pred))\n",
    "print('F2 Score: ',fbeta_score(y_pred=pred, y_true=y_test.values, beta=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6efe4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [    \n",
    "    {'LR__penalty' : ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'LR__C' : [0.01, 0.1, 1, 10, 100],\n",
    "    'LR__solver' : ['lbfgs','newton-cg','liblinear'],\n",
    "    'LR__max_iter' : [100, 1000,2500, 5000]\n",
    "    }\n",
    "]\n",
    "clf_log.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db58375d",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [    \n",
    "    {'penalty' : ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'C' : [0.01, 0.1, 1, 10],\n",
    "    'solver' : ['lbfgs','newton-cg','liblinear'],\n",
    "    'max_iter' : [10, 100, 1000]\n",
    "    }\n",
    "]\n",
    "log_reg.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b801679c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "log_reg = LogisticRegression()\n",
    "grid = GridSearchCV(log_reg,param_grid)\n",
    "grid.fit(X_train_resh,y_train_resh)\n",
    "grid.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d2b3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_pipeline = Pipeline(steps = [('scale',StandardScaler())\n",
    "                                 ,('LR',LogisticRegression(C=0.1\n",
    "                                                        , max_iter=10\n",
    "                                                        ,penalty='l1'\n",
    "                                                        ,solver = 'liblinear'         \n",
    "                                                        ,random_state=42))])\n",
    "\n",
    "clf_pipeline.fit(X_train_resh,y_train_resh)\n",
    "clf_tuned_pred   = clf_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04336113",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94a0f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,clf_tuned_pred ))\n",
    "\n",
    "print('Accuracy Score: ',accuracy_score(y_test,clf_tuned_pred ))\n",
    "print('F1 Score: ',f1_score(y_test,clf_tuned_pred ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "27f008ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[244670, 118781],\n",
       "       [  2959,   4080]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm1 = confusion_matrix(y_test, pred)\n",
    "cm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "626f3ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118781 Type I errors( False Positives)\n",
      "2959 Type II errors( False Negatives)\n",
      "Sensitivity:  0.5796277880380736\n",
      "Specificity:  0.6731856563883439\n"
     ]
    }
   ],
   "source": [
    "print(cm1[0,1],'Type I errors( False Positives)')\n",
    "print(cm1[1,0],'Type II errors( False Negatives)')\n",
    "           \n",
    "print('Sensitivity: ',cm1[1,1]/(float(cm1[1,1]+cm1[1,0])))\n",
    "print('Specificity: ',cm1[0,0]/(float(cm1[0,0]+cm1[0,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984e56dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c2f9fb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(740980, 3)\n",
      "(740980,)\n"
     ]
    }
   ],
   "source": [
    "#Create independent and Dependent Features\n",
    "#columns = df.columns.tolist()\n",
    "\n",
    "# Remove Target \n",
    "#columns = [c for c in columns if c not in [\"Subvariant\"]]\n",
    "\n",
    "# Store Target\n",
    "target = \"Subvariant\"\n",
    "\n",
    "# Define a random state \n",
    "state = np.random.RandomState(111)\n",
    "\n",
    "LABELS = ['ORF1ab','N gene','S gene']\n",
    "\n",
    "X = df_train[LABELS]\n",
    "Y = df_train[target]\n",
    "\n",
    "X_outliers = state.uniform(low=0, high=1, size=(X.shape[0], X.shape[1]))\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ef4818",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly = df_train[df_train.Subvariant==1].drop(['Delta', 'Symptomatic', 'Patient_Sex'], axis=1)\n",
    "#.drop('Specimen_Date', axis=1)\n",
    "normal = df_train[df_train.Subvariant==0].drop(['Delta', 'Symptomatic', 'Patient_Sex'], axis=1)\n",
    "#.drop('Specimen_Date', axis=1)\n",
    "outlier_fraction = len(anomaly)/float(len(normal))\n",
    "outlier_fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c420c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, normal_test, _, _ = train_test_split(normal, normal, test_size=.5, random_state=42)\n",
    "\n",
    "normal_valid, normal_test, _, _ = train_test_split(normal_test, normal_test, test_size=.5, random_state=42)\n",
    "anormal_valid, anormal_test, _, _ = train_test_split(anomaly, anomaly, test_size=.5, random_state=42)\n",
    "\n",
    "train = df_train\n",
    "valid = normal_valid.append(anormal_valid).sample(frac=1).reset_index(drop=True)\n",
    "test = normal_test.append(anormal_test).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print('Train: ', train.shape)\n",
    "print('Proportion os anomaly in training set: %.2f\\n' % train['Subvariant'].mean())\n",
    "print('Valid: ', valid.shape)\n",
    "print('Proportion os anomaly in validation set: %.2f\\n' % valid['Subvariant'].mean())\n",
    "print('Test:, ', test.shape)\n",
    "print('Proportion os anomaly in test set: %.2f\\n' % test['Subvariant'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e922537",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal.to_csv(\"normal.csv\")\n",
    "anomaly.to_csv(\"anomaly.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "879f421a",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = pd.read_csv(\"normal.csv\", index_col=0)\n",
    "anomaly = pd.read_csv(\"anomaly.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1441a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop('SGTF',axis=1)\n",
    "    #['Delta', 'Symptomatic', 'Patient_Sex', 'age_group'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2dd285",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "gmm = GaussianMixture(n_components=3, n_init=4, random_state=42)\n",
    "gmm.fit(train.drop('Subvariant', axis=1).values)\n",
    "print(gmm.score(valid[valid['Subvariant'] == 0].drop('Subvariant', axis=1).values))\n",
    "print(gmm.score(valid[valid['Subvariant'] == 1].drop('Subvariant', axis=1).values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c55df30",
   "metadata": {},
   "outputs": [],
   "source": [
    "tresholds = np.linspace(-400, 0, 100)\n",
    "y_scores = gmm.score_samples(valid.drop('Subvariant', axis=1).values)\n",
    "scores = []\n",
    "for treshold in tresholds:\n",
    "    y_hat = (y_scores < treshold).astype(int)\n",
    "    scores.append([recall_score(y_pred=y_hat, y_true=valid['Subvariant'].values),\n",
    "                 precision_score(y_pred=y_hat, y_true=valid['Subvariant'].values),\n",
    "                 fbeta_score(y_pred=y_hat, y_true=valid['Subvariant'].values, beta=2)])\n",
    "\n",
    "scores = np.array(scores)\n",
    "print(scores[:, 2].max(), scores[:, 2].argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843679fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tresholds, scores[:, 0], label='$Recall$')\n",
    "plt.plot(tresholds, scores[:, 1], label='$Precision$')\n",
    "plt.plot(tresholds, scores[:, 2], label='$F_2$')\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Threshold')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919d0638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    Copyed from a kernel by joparga3 https://www.kaggle.com/joparga3/kernels\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355ffe18",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tresh = tresholds[scores[:, 2].argmax()]\n",
    "y_hat_test = (gmm.score_samples(test.drop('Subvariant', axis=1).values) < final_tresh).astype(int)\n",
    "\n",
    "print('Final threshold: %f' % final_tresh)\n",
    "print('Test Recall Score: %.3f' % recall_score(y_pred=y_hat_test, y_true=test['Subvariant'].values))\n",
    "print('Test Precision Score: %.3f' % precision_score(y_pred=y_hat_test, y_true=test['Subvariant'].values))\n",
    "print('Test F2 Score: %.3f' % fbeta_score(y_pred=y_hat_test, y_true=test['Subvariant'].values, beta=2))\n",
    "\n",
    "cnf_matrix = confusion_matrix(test['Subvariant'].values, y_hat_test)\n",
    "plot_confusion_matrix(cnf_matrix, classes=['Normal','Anormal'], title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83c4d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "np.random.seed(42)\n",
    "\n",
    "model = IsolationForest(random_state=42, n_jobs=4, max_samples=train.shape[0], bootstrap=True, n_estimators=50)\n",
    "model.fit(train.drop('Subvariant', axis=1).values)\n",
    "print(model.decision_function(valid[valid['Subvariant'] == 0].drop('Subvariant', axis=1).values).mean())\n",
    "print(model.decision_function(valid[valid['Subvariant'] == 1].drop('Subvariant', axis=1).values).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c358ca8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tresholds = np.linspace(-.2, .2, 200)\n",
    "y_scores = model.decision_function(valid.drop('Subvariant', axis=1).values)\n",
    "scores = []\n",
    "for treshold in tresholds:\n",
    "    y_hat = (y_scores < treshold).astype(int)\n",
    "    scores.append([recall_score(y_pred=y_hat, y_true=valid['Subvariant'].values),\n",
    "                 precision_score(y_pred=y_hat, y_true=valid['Subvariant'].values),\n",
    "                 fbeta_score(y_pred=y_hat, y_true=valid['Subvariant'].values, beta=2)])\n",
    "\n",
    "scores = np.array(scores)\n",
    "print(scores[:, 2].max(), scores[:, 2].argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1198e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tresholds, scores[:, 0], label='$Recall$')\n",
    "plt.plot(tresholds, scores[:, 1], label='$Precision$')\n",
    "plt.plot(tresholds, scores[:, 2], label='$F_2$')\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Threshold')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ed245b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tresh = tresholds[scores[:, 2].argmax()]\n",
    "y_hat_test = (model.decision_function(test.drop('Subvariant', axis=1).values) < final_tresh).astype(int)\n",
    "\n",
    "print('Final threshold: %f' % final_tresh)\n",
    "print('Test Recall Score: %.3f' % recall_score(y_pred=y_hat_test, y_true=test['Subvariant'].values))\n",
    "print('Test Precision Score: %.3f' % precision_score(y_pred=y_hat_test, y_true=test['Subvariant'].values))\n",
    "print('Test F2 Score: %.3f' % fbeta_score(y_pred=y_hat_test, y_true=test['Subvariant'].values, beta=2))\n",
    "\n",
    "cnf_matrix = confusion_matrix(test['Subvariant'].values, y_hat_test)\n",
    "plot_confusion_matrix(cnf_matrix, classes=['Normal','Anormal'], title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3c2d18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3b739b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb0c272",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a4199a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b1044b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename = 'clf_pipeline_tuned.sav'\n",
    "#pickle.dump(clf_pipeline, open(filename, 'wb'))\n",
    "#loaded_model = pickle.load(open(filename, 'rb'))\n",
    "#result = loaded_model.score(X_test, Y_test)\n",
    "#print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7226ea2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30b08d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ce9dd322",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Novelty Detection\n",
    "\n",
    "classifiers = {\n",
    "    \"Isolation Forest\":IsolationForest(n_estimators=10, max_samples=len(X), \n",
    "                                       verbose=0),\n",
    "    \"Local Outlier Factor\":LocalOutlierFactor(n_neighbors=20, algorithm='auto', \n",
    "                                              leaf_size=30, metric='minkowski',\n",
    "                                              p=2, metric_params=None, contamination=0.025),\n",
    "   # \"EllipticEnvelope\": EllipticEnvelope(contamination=0.025, random_state=111)\n",
    "    \n",
    "    \"Support Vector Machine\":OneClassSVM(degree=3, gamma=0.1,nu=0.025, \n",
    "                                         max_iter=-1)\n",
    "   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34e591e",
   "metadata": {},
   "outputs": [],
   "source": [
    "iForest = IsolationForest()\n",
    "iForest.fit(X)\n",
    "iForest.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdaf131",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8ca8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "iForest = IsolationForest(n_estimators=10, max_samples=len(X), \n",
    "                                       verbose=0, contamination = 0.025)\n",
    "iForest.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9bec66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db21ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tresholds = np.linspace(-.2, .2, 200)\n",
    "y_scores = iForest.decision_function(X)\n",
    "scores = []\n",
    "for treshold in tresholds:\n",
    "    y_hat = (y_scores < treshold).astype(int)\n",
    "    scores.append([recall_score(y_pred=y_hat, y_true=Y),\n",
    "                 precision_score(y_pred=y_hat, y_true=Y),\n",
    "                 fbeta_score(y_pred=y_hat, y_true=Y, beta=2)])\n",
    "\n",
    "scores = np.array(scores)\n",
    "print(scores[:, 2].max(), scores[:, 2].argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4806bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "socres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b2aad4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2feae862",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_nov = [    \n",
    "    { 'contamination': [0,0.02,0.05]\n",
    "    }\n",
    "]\n",
    "\n",
    "## Isolation forest doesnt have its own sore, create my own\n",
    "def scorer_f(estimator, X):   # my own scorer\n",
    "      return np.mean(estimator.score_samples(X))\n",
    "\n",
    "grid_iForest = GridSearchCV(iForest,param_grid_nov, scorer_f)\n",
    "grid_iForest.fit(X_train,y_train)\n",
    "grid_iForest.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf00a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a566430",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "clf_cov = EllipticEnvelope(contamination=0.025, random_state=111).fit(X)\n",
    "\n",
    "y_pred_cov = clf_cov.predict(X)\n",
    "t1 = time.time()\n",
    "print(f'time taken {(t1 - t0)}')\n",
    "filename = 'cov.sav'\n",
    "pickle.dump(clf_cov, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7336cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=\"cov.sav\"\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "#result = loaded_model.predict(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f8dd2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7611c3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_cov[y_pred_cov == 1] = 0\n",
    "y_pred_cov[y_pred_cov == -1] = 1\n",
    "n_errors = (y_pred_cov != Y).sum()\n",
    "# Run Classification Metrics\n",
    "print(\"{}: {}\".format(clf_cov,n_errors))\n",
    "print(\"Accuracy Score :\")\n",
    "print(accuracy_score(Y,y_pred_cov))\n",
    "print(\"Classification Report :\")\n",
    "print(classification_report(Y,y_pred_cov))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b2a389",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_if = IsolationForest(n_estimators=100, max_samples='auto', \\\n",
    "                        max_features=1.0, contamination=0.0001, bootstrap=False, n_jobs=-1, random_state=111, verbose=0)\n",
    "\n",
    "clf_if.fit(X)\n",
    "scores_prediction = clf_if.decision_function(X)\n",
    "y_pred_if = clf_if.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933ace96",
   "metadata": {},
   "outputs": [],
   "source": [
    "(unique, counts) = np.unique(y_pred_if, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741fdb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_if\n",
    "y_pred_if[y_pred_if == 1] = 0\n",
    "y_pred_if[y_pred_if == -1] = 1\n",
    "n_errors = (y_pred_if != Y).sum()\n",
    "# Run Classification Metrics\n",
    "print(\"{}: {}\".format(clf_if,n_errors))\n",
    "print(\"Accuracy Score :\")\n",
    "print(accuracy_score(Y,y_pred_if))\n",
    "print(\"Classification Report :\")\n",
    "print(classification_report(Y,y_pred_if))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea667685",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=\"iForest.sav\"\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.predict(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9b8d6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c003e2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_if[y_pred_cov == 1] = 0\n",
    "y_pred_if[y_pred_cov == -1] = 1\n",
    "n_errors = (y_pred_cov != Y).sum()\n",
    "# Run Classification Metrics\n",
    "print(\"{}: {}\".format(clf_cov,n_errors))\n",
    "print(\"Accuracy Score :\")\n",
    "print(accuracy_score(Y,y_pred_cov))\n",
    "print(\"Classification Report :\")\n",
    "print(classification_report(Y,y_pred_cov))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c3a65443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken 12.5560302734375\n",
      "Isolation Forest: 25941\n",
      "Accuracy Score :\n",
      "0.9649909579205916\n",
      "Classification Report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98    726902\n",
      "           1       0.13      0.14      0.13     14078\n",
      "\n",
      "    accuracy                           0.96    740980\n",
      "   macro avg       0.55      0.56      0.56    740980\n",
      "weighted avg       0.97      0.96      0.97    740980\n",
      "\n",
      "time taken 13.666722536087036\n",
      "Local Outlier Factor: 14078\n",
      "Accuracy Score :\n",
      "0.9810008367297363\n",
      "Classification Report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99    726902\n",
      "           1       0.00      0.00      0.00     14078\n",
      "\n",
      "    accuracy                           0.98    740980\n",
      "   macro avg       0.49      0.50      0.50    740980\n",
      "weighted avg       0.96      0.98      0.97    740980\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-5098d550def0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mclf_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Support Vector Machine\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, **params)\u001b[0m\n\u001b[1;32m   1375\u001b[0m         \"\"\"\n\u001b[1;32m   1376\u001b[0m         super().fit(X, np.ones(_num_samples(X)),\n\u001b[0;32m-> 1377\u001b[0;31m                     sample_weight=sample_weight, **params)\n\u001b[0m\u001b[1;32m   1378\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffset_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_intercept_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    283\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time \n",
    "n_outliers = len(anomaly)\n",
    "for i, (clf_name,clf) in enumerate(classifiers.items()):\n",
    "    #Fit the data and tag outliers\n",
    "    if clf_name == \"Local Outlier Factor\":\n",
    "        t0 = time.time()\n",
    "        y_pred_lof = clf.fit_predict(X)\n",
    "        scores_prediction = clf.negative_outlier_factor_\n",
    "        t1 = time.time()\n",
    "        print(f'time taken {(t1 - t0)}')\n",
    "        filename = 'LOF.sav'\n",
    "       # pickle.dump(clf, open(filename, 'wb'))\n",
    "    elif clf_name == \"Support Vector Machine\":\n",
    "        t0 = time.time()\n",
    "        clf.fit(X)\n",
    "        y_pred = clf.predict(X)\n",
    "        t1 = time.time()\n",
    "        print(f'time taken {(t1 - t0)}')\n",
    "        filename = 'OCSVM.sav'\n",
    "    #    pickle.dump(clf, open(filename, 'wb'))\n",
    "    \n",
    "    else:    \n",
    "        t0 = time.time()\n",
    "        clf.fit(X)\n",
    "        scores_prediction = clf.decision_function(X)\n",
    "        y_pred = clf.predict(X)\n",
    "        t1 = time.time()\n",
    "        print(f'time taken {(t1 - t0)}')\n",
    "       # filename = 'iForest.sav'\n",
    "      #  pickle.dump(clf, open(filename, 'wb'))\n",
    "        ## use SHAP to interpret model\n",
    "       # exp = shap.TreeExplainer(clf) #Explainer\n",
    "       # shap_values = exp.shap_values(X)  #Calculate SHAP values\n",
    "        #shap.initjs()\n",
    "    #Reshape the prediction values to 0 for Valid transactions , 1 for Fraud transactions\n",
    "    y_pred[y_pred == 1] = 0\n",
    "    y_pred[y_pred == -1] = 1\n",
    "    n_errors = (y_pred != Y).sum()\n",
    "    # Run Classification Metrics\n",
    "    print(\"{}: {}\".format(clf_name,n_errors))\n",
    "    print(\"Accuracy Score :\")\n",
    "    print(accuracy_score(Y,y_pred))\n",
    "    print(\"Classification Report :\")\n",
    "    print(classification_report(Y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877ee47a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
